{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install syllapy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pACvSarUcW8V",
        "outputId": "be3276b2-be3a-42d5-af5c-d800015d0bd2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting syllapy\n",
            "  Downloading syllapy-0.7.2-py3-none-any.whl.metadata (854 bytes)\n",
            "Downloading syllapy-0.7.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: syllapy\n",
            "Successfully installed syllapy-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "H6KjmYf5LPTO"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import syllapy\n",
        "from textblob import TextBlob\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ydZYs4lMMZA",
        "outputId": "4ee14f78-85f5-456f-c8ff-11d751a3d68f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SgyIpfZUiLh",
        "outputId": "4458237e-5f81-4502-eb90-5ffd2315cef8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "zP1jPpZXRAS3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_word_list(filename):\n",
        "    with open(filename, 'r', encoding = 'latin -1') as file:\n",
        "        return set(word.strip().lower() for word in file.readlines())\n",
        "\n",
        "# Load positive and negative words\n",
        "positive_words = load_word_list(\"positive-words.txt\")\n",
        "negative_words = load_word_list(\"negative-words.txt\")"
      ],
      "metadata": {
        "id": "Dgt8aX41QrLa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the Stop words File"
      ],
      "metadata": {
        "id": "meWR3ZpHSma_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_stop_words = nltk_stop_words.union(positive_words).union(negative_words)\n",
        "\n",
        "print(f\"Total custom stop-words: {len(custom_stop_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_hFllKVQ9lG",
        "outputId": "f61bd8b1-dac4-4db9-b364-461124b99d24"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total custom stop-words: 6964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text, stop_words):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    words = word_tokenize(text)  # Tokenize text into words\n",
        "    filtered_words = [word for word in words if word not in stop_words]  # Remove stop-words\n",
        "    return filtered_words"
      ],
      "metadata": {
        "id": "DLO9z0JKRE-D"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(text):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    words = clean_text(text, custom_stop_words)\n",
        "\n",
        "    # Positive and negative scores\n",
        "    positive_score = sum(1 for word in words if word in positive_words)\n",
        "    negative_score = sum(1 for word in words if word in negative_words)\n",
        "\n",
        "    # Word and sentence metrics\n",
        "    total_word_count = len(words)\n",
        "    avg_sentence_length = total_word_count / len(sentences)\n",
        "\n",
        "    # Complex words: Words with more than 2 syllables\n",
        "    def count_syllables(word):\n",
        "        vowels = \"aeiouy\"\n",
        "        word = word.lower()\n",
        "        count = sum(1 for i in range(len(word)) if word[i] in vowels and (i == 0 or word[i-1] not in vowels))\n",
        "        return count\n",
        "\n",
        "    complex_words = [word for word in words if count_syllables(word) > 2]\n",
        "    complex_word_count = len(complex_words)\n",
        "    percent_complex_words = (complex_word_count / total_word_count) * 100 if total_word_count > 0 else 0\n",
        "\n",
        "    # Fog Index\n",
        "    fog_index = 0.4 * (avg_sentence_length + percent_complex_words)\n",
        "\n",
        "    # Personal pronouns\n",
        "    personal_pronouns = ['i', 'we', 'my', 'ours', 'us', 'you', 'he', 'she', 'him', 'her', 'they', 'them']\n",
        "    personal_pronoun_count = sum(1 for word in words if word in personal_pronouns)\n",
        "\n",
        "    return {\n",
        "        \"positive_score\": positive_score,\n",
        "        \"negative_score\": negative_score,\n",
        "        \"avg_sentence_length\": avg_sentence_length,\n",
        "        \"percent_complex_words\": percent_complex_words,\n",
        "        \"fog_index\": fog_index,\n",
        "        \"avg_words_per_sentence\": avg_sentence_length,\n",
        "        \"complex_word_count\": complex_word_count,\n",
        "        \"total_word_count\": total_word_count,\n",
        "        \"personal_pronoun_count\": len(personal_pronouns)\n",
        "    }\n",
        "def syllable_count(word):\n",
        "    word = word.lower()\n",
        "    vowels = \"aeiou\"\n",
        "    count = 0\n",
        "    prev_char_is_vowel = False\n",
        "    for char in word:\n",
        "        if char in vowels:\n",
        "            if not prev_char_is_vowel:\n",
        "                count += 1\n",
        "            prev_char_is_vowel = True\n",
        "        else:\n",
        "            prev_char_is_vowel = False\n",
        "    if word.endswith(\"e\"):\n",
        "        count = max(1, count - 1)\n",
        "    return count"
      ],
      "metadata": {
        "id": "Ifo5Ix8Yeu3Y"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File 1"
      ],
      "metadata": {
        "id": "hlQlh-_eZuNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/10744.4.txt'\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "  text = file.read()\n",
        "  # Calculate metrics\n",
        "  metric = calculate_metrics(text)\n",
        "  print(metric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz-RR8XJSv1k",
        "outputId": "ce810036-f0c3-4baf-faf2-2b6e4b7ab8bd"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'positive_score': 0, 'negative_score': 0, 'avg_sentence_length': 9.646153846153846, 'percent_complex_words': 38.43700159489633, 'fog_index': 19.23326217642007, 'avg_words_per_sentence': 9.646153846153846, 'complex_word_count': 241, 'total_word_count': 627, 'personal_pronoun_count': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File 2"
      ],
      "metadata": {
        "id": "afRaZUZifjR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/11206.2.txt'\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "  text = file.read()\n",
        "  # Calculate metrics\n",
        "  metric = calculate_metrics(text)\n",
        "  print(metric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc1q_CBjflFM",
        "outputId": "c0c1ccdc-d128-44bf-b39f-cee27a6b3a8d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'positive_score': 0, 'negative_score': 0, 'avg_sentence_length': 8.195652173913043, 'percent_complex_words': 44.03183023872679, 'fog_index': 20.890992965055933, 'avg_words_per_sentence': 8.195652173913043, 'complex_word_count': 166, 'total_word_count': 377, 'personal_pronoun_count': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File 3"
      ],
      "metadata": {
        "id": "1bo9ldiyf4cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/12129.8.txt'\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "  text = file.read()\n",
        "  # Calculate metrics\n",
        "  metric = calculate_metrics(text)\n",
        "  print(metric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twW9kt3bf3WM",
        "outputId": "bf6a52ca-7d75-4b02-d928-401d200181de"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'positive_score': 0, 'negative_score': 0, 'avg_sentence_length': 9.72972972972973, 'percent_complex_words': 33.05555555555556, 'fog_index': 17.114114114114113, 'avg_words_per_sentence': 9.72972972972973, 'complex_word_count': 119, 'total_word_count': 360, 'personal_pronoun_count': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File 4"
      ],
      "metadata": {
        "id": "j_KO_i3Ff4M3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/123.0.txt'\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "  text = file.read()\n",
        "  # Calculate metrics\n",
        "  metric = calculate_metrics(text)\n",
        "  print(metric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-36A2B0Tf394",
        "outputId": "a4bbd703-6b0c-4f16-f292-6915eb074682"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'positive_score': 0, 'negative_score': 0, 'avg_sentence_length': 11.15, 'percent_complex_words': 49.66367713004484, 'fog_index': 24.325470852017936, 'avg_words_per_sentence': 11.15, 'complex_word_count': 443, 'total_word_count': 892, 'personal_pronoun_count': 12}\n"
          ]
        }
      ]
    }
  ]
}